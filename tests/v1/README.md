## V1 Test Scenarios

> **Status convention:**
>
> - `âœ… Asserted` â€” scenario runs AND outcome is explicitly asserted on the created run
> - `ðŸ”„ Exercised` â€” scenario runs but outcome is not asserted (smoke test / no-crash check)
> - `âŒ Untested` â€” no test covers this scenario

> **Note:** An autouse `no_error_logs` fixture in `test_from_openhtf.py` asserts zero ERROR-level log records for every test in `TestCreateRunFromOpenHTF`. This guards against silent failures but does not verify run properties.

### 1. End-to-End Workflows

| Scenario                                         | Status       | File                     | Function Name                        | Details                                                                                              |
| ------------------------------------------------ | ------------ | ------------------------ | ------------------------------------ | ---------------------------------------------------------------------------------------------------- |
| Full test with all measurement types             | âœ… Asserted  | `test_all_the_things.py` | `test_all_the_things`                | Regex, range, dimensions, marginals, attachments â€” phases, values, and validators asserted           |
| Teardown phase executes after test               | âœ… Asserted  | `test_all_the_things.py` | `test_all_the_things`                | PhaseGroup.with_teardown runs teardown; phase present and PASS asserted                              |
| Cross-phase data integrity                       | âœ… Asserted  | `test_all_the_things.py` | `test_all_the_things`                | `analysis` phase re-reads measurements and attachments set by earlier phases                         |
| JSON output callback generates file              | ðŸ”„ Exercised | `test_all_the_things.py` | `test_all_the_things`                | OutputToJSON callback added but file existence is not asserted                                       |
| Streaming mode                                   | âœ… Asserted  | `test_all_the_things.py` | `test_all_the_things` (parametrized) | Runs with `stream=True`; full assertions applied                                                     |
| Non-streaming mode                               | âœ… Asserted  | `test_all_the_things.py` | `test_all_the_things` (parametrized) | Runs with `stream=False`; full assertions applied                                                    |
| Generic PCB test procedure                       | âœ… Asserted  | `test_generic.py`        | `test_generic`                       | Firmware, button, voltage, overcurrent, efficiency, visual ctrl. Deterministic values â€” always PASS. |
| Run with part number, revision, and batch number | âœ… Asserted  | `test_generic.py`        | `test_generic`                       | Asserts all three fields on created run                                                              |

### 2. Run Creation from OpenHTF Reports

| Scenario                                          | Status       | File                   | Function Name                                  | Details                                                                                         |
| ------------------------------------------------- | ------------ | ---------------------- | ---------------------------------------------- | ----------------------------------------------------------------------------------------------- |
| Basic OpenHTF run creation                        | ðŸ”„ Exercised | `test_from_openhtf.py` | `test_basic_openhtf_run_creation`              | Single power-on phase â†’ run created; no run property assertions                                 |
| Run creation with file attachments                | ðŸ”„ Exercised | `test_from_openhtf.py` | `test_openhtf_run_creation_with_attachments`   | Text file + JPEG image attached; no run property assertions                                     |
| Run creation with multi-dimensional measurements  | ðŸ”„ Exercised | `test_from_openhtf.py` | `test_openhtf_multidimensional_measurements`   | Power time series, temperature profiles, frequency response; no run property assertions         |
| Import from pre-existing OpenHTF JSON report file | âœ… Asserted  | `test_from_openhtf.py` | `test_create_run_from_openhtf_json_report`     | JSON file â†’ `create_run_from_openhtf_report()` â†’ run ID, serial_number, part_number asserted    |
| Run creation with `upload` callback directly      | ðŸ”„ Exercised | `test_from_openhtf.py` | `test_upload_callback_without_context_manager` | `upload` class as output callback without TofuPilot context manager; no run property assertions |

### 3. Measurements

| Scenario                                         | Status       | File                         | Function Name             | Details                                                                                                               |
| ------------------------------------------------ | ------------ | ---------------------------- | ------------------------- | --------------------------------------------------------------------------------------------------------------------- |
| Multi-dimensional measurements (1D, 2D, 3D)      | ðŸ”„ Exercised | `test_multi_dimensions.py`   | `test_multi_dimensions`   | Voltage over time, sinus, negative axes, current/voltage/ohm; phase names asserted but measurement values have a TODO |
| Multiple measurement types in single run         | âœ… Asserted  | `test_multi_measurements.py` | `test_multi_measurements` | String, boolean, phase result, numeric with limits, dimensioned; phase names and outcomes asserted                    |
| Deliberately failing measurements â†’ FAIL outcome | âœ… Asserted  | `test_multi_measurements.py` | `test_multi_measurements` | Wrong types trigger per-phase FAIL, others remain PASS                                                                |
| Measurements with range validators               | âœ… Asserted  | `test_all_the_things.py`     | `test_all_the_things`     | `in_range`, `matches_regex`, `equals` â€” validators presence asserted on run                                           |
| Measurements with marginal arguments             | âœ… Asserted  | `test_all_the_things.py`     | `test_all_the_things`     | `marginal_minimum` / `marginal_maximum` replaced at runtime â€” validators and values asserted on run                   |
| Measurement units preserved on created run       | âœ… Asserted  | `test_multi_measurements.py` | `test_multi_measurements` | `with_units()` values (V, A, %) verified on run measurements                                                          |
| Phase with no measurements                       | âœ… Asserted  | `test_multi_measurements.py` | `test_multi_measurements` | Empty measurement list and PASS outcome verified                                                                      |

### 4. Logging

| Scenario              | Status      | File             | Function Name | Details                                          |
| --------------------- | ----------- | ---------------- | ------------- | ------------------------------------------------ |
| INFO log captured     | âœ… Asserted | `test_logger.py` | `test_logger` | `logger.info()` â†’ level=INFO in run logs         |
| ERROR log captured    | âœ… Asserted | `test_logger.py` | `test_logger` | `logger.error()` â†’ level=ERROR in run logs       |
| WARNING log captured  | âœ… Asserted | `test_logger.py` | `test_logger` | `logger.warning()` â†’ level=WARNING in run logs   |
| CRITICAL log captured | âœ… Asserted | `test_logger.py` | `test_logger` | `logger.critical()` â†’ level=CRITICAL in run logs |
| DEBUG log captured    | âœ… Asserted | `test_logger.py` | `test_logger` | `logger.debug()` â†’ level=DEBUG in run logs       |

### 5. Procedure Metadata

| Scenario                                      | Status      | File                        | Function Name                                | Details                                                      |
| --------------------------------------------- | ----------- | --------------------------- | -------------------------------------------- | ------------------------------------------------------------ |
| Procedure version passed through to TofuPilot | âœ… Asserted | `test_procedure_version.py` | `test_procedure_version` | Deterministic `check_button` phase, asserts version `1.2.20` |

### 6. Serial Number Regex

| Scenario                                                     | Status      | File                          | Function Name                              | Details                                                                  |
| ------------------------------------------------------------ | ----------- | ----------------------------- | ------------------------------------------ | ------------------------------------------------------------------------ |
| Missing part number without regex config returns clear error | âœ… Asserted | `test_regex_serial_number.py` | `test_no_part_number_without_regex_config` | No `part_number`, no org regex â†’ server rejects with "part number" error |

### 7. Attachments

| Scenario                           | Status       | File                     | Function Name                                | Details                                                           |
| ---------------------------------- | ------------ | ------------------------ | -------------------------------------------- | ----------------------------------------------------------------- |
| File attachment (image)            | âœ… Asserted  | `test_all_the_things.py` | `test_all_the_things`                        | `attach_from_file("oscilloscope.jpeg")` â€” name asserted on run    |
| Binary data attachment             | âœ… Asserted  | `test_all_the_things.py` | `test_all_the_things`                        | `attach("name", data.encode("utf-8"))` â€” name asserted on run     |
| Multiple file types (text + image) | ðŸ”„ Exercised | `test_from_openhtf.py`   | `test_openhtf_run_creation_with_attachments` | `.txt` + `.jpeg` attached in same run; no run property assertions |

### 8. OpenHTF-Specific Features

| Scenario                                      | Status       | File                       | Function Name                            | Details                                                                                                                   |
| --------------------------------------------- | ------------ | -------------------------- | ---------------------------------------- | ------------------------------------------------------------------------------------------------------------------------- |
| Skipped phase included in test definition     | ðŸ”„ Exercised | `test_all_the_things.py`   | `test_all_the_things`                    | `@htf.PhaseOptions(run_if=lambda: False)` â€” phase defined but neither presence nor SKIP outcome asserted on run           |
| Sub-units via OpenHTF `htf.Test()`            | ðŸ”„ Exercised | `test_openhtf_features.py` | `test_sub_units_via_openhtf`             | Sub-unit created via V2 client, linked via `sub_units` metadata â€” run creation asserted but sub-unit linkage not verified |
| `allow_nan` in OpenHTF JSON serialization     | ðŸ”„ Exercised | `test_openhtf_features.py` | `test_allow_nan_in_openhtf_json`         | NaN measurement uploaded with `allow_nan=True` on `upload` callback; no run property assertions                           |
| PhaseOptions timeout triggers correct outcome | âœ… Asserted  | `test_openhtf_features.py` | `test_phase_timeout_outcome`             | `@htf.PhaseOptions(timeout_s=1)` â†’ asserts timed-out phase outcome is not PASS                                            |
| Phase with PhaseResult.STOP halts execution   | âœ… Asserted  | `test_openhtf_features.py` | `test_phase_result_stop_halts_execution` | `PhaseResult.STOP` â†’ asserts subsequent phase not present in run phases                                                   |

### 9. Direct Client API â€” `create_run()` (POST /v1/runs)

> 62k calls/year in prod.

#### 9a. Core Run Creation

| Scenario                              | Status      | File                 | Function Name                            | Details                                                                                                     |
| ------------------------------------- | ----------- | -------------------- | ---------------------------------------- | ----------------------------------------------------------------------------------------------------------- |
| Minimal PASS run                      | âœ… Asserted | `test_create_run.py` | `test_minimal_pass_run`                  | `create_run({"serial_number": "SN"}, run_passed=True)` â†’ response has `id`, V2 lookup confirms outcome=PASS |
| Minimal FAIL run                      | âœ… Asserted | `test_create_run.py` | `test_minimal_fail_run`                  | `run_passed=False` â†’ outcome stored as FAIL on created run                                                  |
| All UnitUnderTest fields roundtrip    | âœ… Asserted | `test_create_run.py` | `test_all_unit_fields_roundtrip`         | serial_number, part_number, revision, batch_number verified on created run (`part_name` deprecated by API)  |
| `started_at` and `duration` preserved | âœ… Asserted | `test_create_run.py` | `test_started_at_and_duration_preserved` | Datetime and timedelta roundtrip â€” created run timestamps match input values                                |

#### 9b. Procedure Resolution

| Scenario                               | Status      | File                           | Function Name                     | Details                                                                               |
| -------------------------------------- | ----------- | ------------------------------ | --------------------------------- | ------------------------------------------------------------------------------------- |
| Procedure resolved by `procedure_name` | âœ… Asserted | `test_create_run_procedure.py` | `test_procedure_resolved_by_name` | `procedure_name` alongside `procedure_id` â†’ run created (API requires `procedure_id`) |
| Procedure resolved by `procedure_id`   | âœ… Asserted | `test_create_run_procedure.py` | `test_procedure_resolved_by_id`   | Existing procedure matched by ID; run linked correctly                                |
| `procedure_version` stored on run      | âœ… Asserted | `test_create_run_procedure.py` | `test_procedure_version_stored`   | Version tag verified on created run via V2 lookup                                     |

#### 9c. Phases and Measurements

| Scenario                                           | Status       | File                        | Function Name                         | Details                                                                              |
| -------------------------------------------------- | ------------ | --------------------------- | ------------------------------------- | ------------------------------------------------------------------------------------ |
| Phases with PASS and FAIL outcomes preserved       | âœ… Asserted  | `test_create_run_phases.py` | `test_phases_with_mixed_outcomes`     | Multiple Phase dicts with mixed outcomes â†’ each phase outcome matches on created run |
| Measurement with limits (lower_limit, upper_limit) | âœ… Asserted  | `test_create_run_phases.py` | `test_measurement_with_limits`        | Limits roundtrip correctly; measured_value and validators verified                   |
| Measurement units preserved                        | âœ… Asserted  | `test_create_run_phases.py` | `test_measurement_units_preserved`    | `units` field on Measurement dict verified on created run (V, A, %)                  |
| Measurement outcomes (PASS, FAIL, UNSET) preserved | âœ… Asserted  | `test_create_run_phases.py` | `test_measurement_outcomes_preserved` | Each MeasurementOutcome enum value stored and retrievable                            |

#### 9d. Attachments (direct file paths)

| Scenario                                         | Status      | File                             | Function Name                        | Details                                                                  |
| ------------------------------------------------ | ----------- | -------------------------------- | ------------------------------------ | ------------------------------------------------------------------------ |
| Single file attachment uploaded and retrievable  | âœ… Asserted | `test_create_run_attachments.py` | `test_single_file_attachment`        | File path in `attachments` list â†’ attachment name appears on created run |
| Multiple file attachments in single run          | âœ… Asserted | `test_create_run_attachments.py` | `test_multiple_file_attachments`     | Several file paths â†’ all attachment names present on created run         |
| Oversized file (>10MB) rejected with clear error | âœ… Asserted | `test_create_run_attachments.py` | `test_oversized_file_rejected`       | `validate_files()` catches size violation â†’ `SystemExit` raised          |
| Too many attachments (>100) rejected             | âœ… Asserted | `test_create_run_attachments.py` | `test_too_many_attachments_rejected` | Exceeding `CLIENT_MAX_ATTACHMENTS` â†’ `SystemExit` raised                 |

#### 9e. Logs (direct)

| Scenario                                     | Status      | File                      | Function Name                        | Details                                                                                |
| -------------------------------------------- | ----------- | ------------------------- | ------------------------------------ | -------------------------------------------------------------------------------------- |
| Log entries with all levels preserved        | âœ… Asserted | `test_create_run_logs.py` | `test_log_levels_preserved`          | Log dicts with DEBUG through CRITICAL â†’ each level and message verified on created run |
| Log timestamps and source metadata preserved | âœ… Asserted | `test_create_run_logs.py` | `test_log_source_metadata_preserved` | `timestamp`, `source_file`, `line_number` roundtrip on created run                     |

#### 9f. Sub-units (direct)

| Scenario                     | Status      | File                           | Function Name                  | Details                                                                                |
| ---------------------------- | ----------- | ------------------------------ | ------------------------------ | -------------------------------------------------------------------------------------- |
| Sub-units linked to main run | âœ… Asserted | `test_create_run_sub_units.py` | `test_sub_units_linked_to_run` | Pre-create sub-unit via V2, then `sub_units=[{...}]` â†’ linkage verified on created run |

### 10. Direct Client API â€” `get_runs()` (GET /v1/runs)

> 8k calls/year in prod.

| Scenario                                     | Status      | File               | Function Name                          | Details                                                                                     |
| -------------------------------------------- | ----------- | ------------------ | -------------------------------------- | ------------------------------------------------------------------------------------------- |
| Returns runs for known serial number         | âœ… Asserted | `test_get_runs.py` | `test_returns_run_for_known_serial`    | Create a run, then `get_runs(serial)` â†’ result contains the run ID                         |
| Response structure matches `GetRunsResponse` | âœ… Asserted | `test_get_runs.py` | `test_response_structure`              | `success`, `result` list with run objects containing id, outcome, unit with serial_number   |
| Multiple runs for same serial number         | âœ… Asserted | `test_get_runs.py` | `test_multiple_runs_for_same_serial`   | Create two runs for same serial â†’ `get_runs()` returns both IDs                            |
| Nonexistent serial number â†’ empty result     | âœ… Asserted | `test_get_runs.py` | `test_nonexistent_serial_returns_empty`| `get_runs("GHOST-...")` â†’ success with empty result list, no error                          |
| Empty serial_number â†’ client-side error      | âœ… Asserted | `test_get_runs.py` | `test_empty_serial_returns_client_error`| `get_runs("")` â†’ `success=False` with "serial_number" in error message                    |

### 11. Error Handling

| Scenario                                   | Status      | File              | Function Name                  | Details                                                                          |
| ------------------------------------------ | ----------- | ----------------- | ------------------------------ | -------------------------------------------------------------------------------- |
| Invalid API key â†’ authentication error     | âœ… Asserted | `test_errors.py`  | `test_invalid_api_key`         | `api_key="invalid-key-000"` â†’ `success=False`, status 401/403                    |
| Missing `serial_number` in unit_under_test | âœ… Asserted | `test_errors.py`  | `test_missing_serial_number`   | Required field omitted â†’ `success=False`, status 400                             |
| Network timeout                            | âœ… Asserted | `test_errors.py`  | `test_network_timeout`         | Unreachable server â†’ `success=False` with error dict                             |
| Invalid file path in attachments           | âœ… Asserted | `test_errors.py`  | `test_invalid_file_path`       | Nonexistent file path â†’ `FileNotFoundError` raised by `validate_files()`         |

---

## V1 Summary

> **Scenarios vs pytest items:** Each row counts one unique test scenario (multiple rows can map to the same function). V1 has 43 unique test functions â†’ **87 pytest items**: `test_all_the_things` Ã—4 (Ã—2 auth Ã— Ã—2 stream), `test_invalid_api_key` Ã—1, 41 other functions Ã—2 (auth).

| Category                       | Scenarios | Asserted | Exercised | Untested |
| ------------------------------ | --------- | -------- | --------- | -------- |
| End-to-End Workflows           | 8         | 7        | 1         | 0        |
| Run Creation from OpenHTF      | 5         | 1        | 4         | 0        |
| Measurements                   | 7         | 6        | 1         | 0        |
| Logging                        | 5         | 5        | 0         | 0        |
| Procedure Metadata             | 1         | 1        | 0         | 0        |
| Serial Number Regex            | 1         | 1        | 0         | 0        |
| Attachments                    | 3         | 2        | 1         | 0        |
| OpenHTF-Specific Features      | 5         | 2        | 3         | 0        |
| Direct Client â€” `create_run()` | 18        | 18       | 0         | 0        |
| Direct Client â€” `get_runs()`   | 5         | 5        | 0         | 0        |
| Error Handling                 | 4         | 4        | 0         | 0        |
| **Total**                      | **62**    | **52**   | **10**    | **0**    |

- **Asserted**: Scenario runs and outcome is explicitly asserted on the created run
- **Exercised**: Scenario runs but outcome is not asserted (smoke test / no-crash check)
- **Untested**: No test covers this scenario

**V1 Coverage: 52/62 asserted, 10/62 exercised, 0/62 untested**
**Pytest items: 87** (43 functions: 1Ã—4 + 1Ã—1 + 41Ã—2)
